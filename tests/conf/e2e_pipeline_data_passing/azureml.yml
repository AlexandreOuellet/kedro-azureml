azure:
  # Azure subscription ID to use
  subscription_id: "00000000-0000-0000-0000-000000000000"
  # Azure ML Experiment Name
  experiment_name: "kedro-azureml-e2e-pipeline-data-passing"
  # Azure resource group to use
  resource_group: "sandbox-ml-ops"
  # Azure ML Workspace name
  workspace_name: "ml-ops-sandbox"
  # Azure ML Environment to use during pipeline execution
  environment_name: ~
  # Path to directory to upload, or null to disable code upload
  code_directory: null
  # Path to the directory in the Docker image to run the code from
  # Ignored when code_directory is set
  working_directory: /home/kedro_docker
  pipeline_data_passing:
    enabled: true
  # Temporary storage settings - this is used to pass some data between steps
  # if the data is not specified in the catalog directly
  temporary_storage: ~
  compute:
    # Azure compute used for running kedro jobs.
    # Additional compute cluster can be defined here. Individual nodes can reference specific compute clusters by adding
    # the section title (e.g. <your_node_tag>) as a node_tag to their tags list. Nodes without a tag will run on
    # __default__ cluster.
    __default__:
      cluster_name: "kedro-azureml-e2e"
    # <your_node_tag>:
    #   cluster_name: "<your_cluster_name>"
docker:
  # Docker image to use during pipeline execution
  image: "{container_registry}/kedro-azureml-e2e:{image_tag}"
